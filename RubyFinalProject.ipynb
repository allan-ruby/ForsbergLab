{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Biol 696 Final Project: Machine Learning Implementation of Retention Time Data to Assist in Metabolomic Data Processing </h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal of Project: Take data from a publically available database(PredRet), preprocess data to create a data set that a nueral network can use, and tune parameters to try to find the most efficient model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Part 1: Taking rudimentary data, process using open source chemoinformatics packages, pubchempy and rdkit, and create a machine learning dataset</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: In an attempt to make this notebook readable, I pickled the dataframes so you can see what I did without actually having to run the code. I will include the not outputted code in the notebook, and if you want to see it in action, will happily stop by and show you in real time!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Intital Dataset </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                       Name    System Username       RT  Pubchem  \\\n",
      "0           1                epicatechin  FEM_long      jan  20.4650      NaN   \n",
      "1           2                    chrysin  FEM_long      jan  40.8800      NaN   \n",
      "2           3        epicatechin gallate  FEM_long      jan  24.7200      NaN   \n",
      "3           4           epigallocatechin  FEM_long      jan  16.5050      NaN   \n",
      "4           5  epigallo-catechin gallate  FEM_long      jan  22.2925      NaN   \n",
      "\n",
      "                                               InChI            Time  \n",
      "0  InChI=1S/C15H14O6/c16-8-4-11(18)9-6-13(20)15(2...  5/12/2015 4:32  \n",
      "1  InChI=1S/C15H10O4/c16-10-6-11(17)15-12(18)8-13...   9/2/2014 5:20  \n",
      "2  InChI=1S/C22H18O10/c23-11-6-14(25)12-8-19(32-2...   9/2/2014 5:20  \n",
      "3  InChI=1S/C15H14O7/c16-7-3-9(17)8-5-12(20)15(22...   9/2/2014 5:20  \n",
      "4  InChI=1S/C22H18O11/c23-10-5-12(24)11-7-18(33-2...   6/8/2015 7:19  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "initialdata = pd.read_csv('retention_time_testdata.csv')\n",
    "print(initialdata.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown, the data is not even close to being ready for implementation. After EXTENSIVE research, I found the chemoinformatic packages mentioned above. Without going too in depth, I essentially parsed out the InChI column(a compound identifier), put it into pubchempy to get some chemical properties(SMILES key being one), then I put the Smiles key into RDkit to pull an extensive numerical list of chemical properties. The code is as follows, but it will most likely error/not run correctly on your system. It's a definition, so keeping the last line uncommented is recommended "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem.Fingerprints import FingerprintMols\n",
    "from rdkit.Chem import MACCSkeys\n",
    "import pubchempy as pcp\n",
    "import pandas as pd\n",
    "from rdkit.Chem.EState import Fingerprinter\n",
    "import numpy as np\n",
    "from rdkit.Chem import Descriptors\n",
    "import pickle\n",
    "#example testing: coing from inchi to testable features\n",
    "\n",
    "def fps_plus_mw(mol):\n",
    "    return np.append(Fingerprinter.FingerprintMol(mol),Descriptors.MolWt(mol))\n",
    "\n",
    "def mol_prop_gen(filename,outputpickle):\n",
    "#loading initial data\n",
    "    dataframe = pd.read_csv(filename)\n",
    "    newdf = pd.DataFrame()\n",
    "    for index, row in dataframe.iterrows():\n",
    "        if index == 0:\n",
    "            inchi = row['InChI']\n",
    "            cmpd = pcp.get_compounds(inchi,'inchi')\n",
    "            props = cmpd[0].to_dict(properties=['cactvs_fingerprint','isomeric_smiles', 'xlogp', 'rotatable_bond_count','charge','complexity','exact_mass','fingerprint'])\n",
    "            smiles=props['isomeric_smiles']\n",
    "            props['mol']=Chem.MolFromSmiles(smiles)\n",
    "            props['RT'] = row['RT']\n",
    "            desc = np.array(fps_plus_mw(props['mol']))\n",
    "            descdf = pd.DataFrame(desc)\n",
    "            descdf = descdf.T\n",
    "            descdf.reindex([index])\n",
    "            newdf=pd.DataFrame(props,index=[index])\n",
    "            finaldf=pd.concat([descdf,newdf],axis=1)\n",
    "        else:\n",
    "            inchi = row['InChI']\n",
    "        try:\n",
    "            cmpd = pcp.get_compounds(inchi,'inchi')\n",
    "        except:\n",
    "            print('line bypassed')\n",
    "            pass\n",
    "        try:\n",
    "            props = cmpd[0].to_dict(properties=['cactvs_fingerprint','isomeric_smiles', 'xlogp', 'rotatable_bond_count','charge','complexity','exact_mass','fingerprint'])\n",
    "        except:\n",
    "            print('line bypassed')\n",
    "            pass\n",
    "        smiles=props['isomeric_smiles']\n",
    "        props['mol']=Chem.MolFromSmiles(smiles)\n",
    "        props['RT'] = row['RT']\n",
    "        newdf=pd.DataFrame(props,index=[index])\n",
    "        desc = np.array(fps_plus_mw(props['mol']))\n",
    "        cols=range(len(desc))\n",
    "        descdf=pd.DataFrame(desc)\n",
    "        descdf = descdf.T\n",
    "        descdf.index = [index]\n",
    "#        descdf = descdf.T\n",
    "#        descdf = pd.DataFrame(descdf, index=[index])\n",
    "        interdf = pd.concat([descdf,newdf],axis=1)\n",
    "        finaldf = finaldf.append(interdf)\n",
    "        print('on index ' + str(index+1) + ' of ' + str(len(dataframe)))\n",
    "        finaldf.to_pickle(outputpickler)\n",
    "\n",
    "\n",
    "#mol_prop_gen('retention_time_testdatashort.csv','test.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1    2    3    4    5    6    7    8    9   ...     \\\n",
      "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0   ...      \n",
      "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   ...      \n",
      "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0   ...      \n",
      "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0   ...      \n",
      "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0   ...      \n",
      "\n",
      "                                  cactvs_fingerprint  \\\n",
      "0  1100000001110000001110000000000000000000000000...   \n",
      "1  1100000001110000001110000000000000000000000000...   \n",
      "2  1110000001111000001111000000000000000000000000...   \n",
      "3  1100000001110000001110000000000000000000000000...   \n",
      "4  1110000001111000001111000000000000000000000000...   \n",
      "\n",
      "                                     isomeric_smiles  xlogp  \\\n",
      "0      C1C(C(OC2=CC(=CC(=C21)O)O)C3=CC(=C(C=C3)O)O)O    0.4   \n",
      "1          C1=CC=C(C=C1)C2=CC(=O)C3=C(C=C(C=C3O2)O)O    2.1   \n",
      "2  C1C(C(OC2=CC(=CC(=C21)O)O)C3=CC(=C(C=C3)O)O)OC...    1.5   \n",
      "3   C1C(C(OC2=CC(=CC(=C21)O)O)C3=CC(=C(C(=C3)O)O)O)O    0.0   \n",
      "4  C1C(C(OC2=CC(=CC(=C21)O)O)C3=CC(=C(C(=C3)O)O)O...    1.2   \n",
      "\n",
      "   rotatable_bond_count  charge  complexity  exact_mass  \\\n",
      "0                     1       0       364.0     290.079   \n",
      "1                     1       0       384.0     254.058   \n",
      "2                     4       0       649.0     442.090   \n",
      "3                     1       0       380.0     306.074   \n",
      "4                     4       0       667.0     458.085   \n",
      "\n",
      "                                         fingerprint  \\\n",
      "0  00000371C0703800000000000000000000000000000000...   \n",
      "1  00000371C0703800000000000000000000000000000000...   \n",
      "2  00000371E0783C00000000000000000000000000000000...   \n",
      "3  00000371C0703800000000000000000000000000000000...   \n",
      "4  00000371E0783C00000000000000000000000000000000...   \n",
      "\n",
      "                                                 mol       RT  \n",
      "0  <rdkit.Chem.rdchem.Mol object at 0x000002A1BA5...  20.4650  \n",
      "1  <rdkit.Chem.rdchem.Mol object at 0x000002A1B95...  40.8800  \n",
      "2  <rdkit.Chem.rdchem.Mol object at 0x000002A1B95...  24.7200  \n",
      "3  <rdkit.Chem.rdchem.Mol object at 0x000002A1B95...  16.5050  \n",
      "4  <rdkit.Chem.rdchem.Mol object at 0x000002A1B95...  22.2925  \n",
      "\n",
      "[5 rows x 169 columns]\n"
     ]
    }
   ],
   "source": [
    "#RUN THIS CELL Dr. Kelley to see data\n",
    "import pickle\n",
    "\n",
    "testdata = pd.read_pickle('my_df.pickle')\n",
    "print(testdata.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this is a lot more computer readable and more suited for a nueral network. Strings and objects, such as column isomeric_smiles and mol are dropped later on, but are nice identifiers for long term use of this data frame. Column RT is the Retention Time, which we will be training on and trying to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>PART 2: Running Nueral Networks</h2>\n",
    "Not entirely sure how this will run on your system Dr. Kelley, and it will take a long time to run. Will include the code if you really want to run it, but I will discuss the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Here's the final code I used to test the best optimizing function for the NN. I suggest not running this in jupyter, but will attach the python file with the submission. Once again, will be happy to do a tutorial in real time. Note How I picked out the results dataframe, which we will look over </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#models in a loop\n",
    "#sgd = keras.optimizers.SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)\n",
    "#rms = keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
    "#ada = keras.optimizers.Adagrad(lr=0.001, epsilon=None, decay=0.0)\n",
    "#adad = keras.optimizers.Adadelta(lr=0.001, rho=0.95, epsilon=None, decay=0.0)\n",
    "#adam = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "#adamax = keras.optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n",
    "#nadam = keras.optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n",
    "#epochs = 10000\n",
    "#finalresults = pd.DataFrame()\n",
    "#optimizers = [ada,adad,adam,adamax,nadam,rms,sgd]\n",
    "#accuracy = []\n",
    "#for count,o in enumerate(optimizers,0):\n",
    "#    model = Sequential()\n",
    "#    model.add(Dense(output_dim=5, input_dim=xvalues.shape[1]))\n",
    "#    model.add(Activation(\"sigmoid\"))\n",
    "#    model.add(Dense(output_dim=1))\n",
    "#    model.add(Activation(\"linear\"))\n",
    "#    model.compile(loss='mean_squared_error', optimizer=o)\n",
    "#    history = model.fit(xtrain, ytrain, nb_epoch=epochs, batch_size=32)\n",
    "#    y_pred = model.predict(xtest)\n",
    "#    y_preddf = pd.DataFrame(y_pred)\n",
    "#    ytest=ytest.reset_index()\n",
    "#    ytest = ytest.drop(['index'],axis=1)\n",
    "#    interdf = pd.concat([ytest,y_preddf],axis=1)\n",
    "#    correct = 0 \n",
    "#    incorrect = 0\n",
    "#    listofper = []\n",
    "#    listofpre = []\n",
    "#    for index,row in interdf.iterrows():\n",
    "#        pred = row[0]\n",
    "#        listofpre.append(pred)\n",
    "#        actu = row['RT']\n",
    "#        percent = ((pred-actu)/actu) * 100\n",
    "#        diff = pred - actu\n",
    "#        listofper.append(percent)\n",
    "#        if diff < 5.00 and diff > -5.00:\n",
    "#            correct += 1\n",
    "#        else:\n",
    "#            incorrect += 1\n",
    "#        samples = len(ytest)\n",
    "#        pos = (correct/samples) *100\n",
    "#    accuracy.append([count,pos])\n",
    "#    resultsdf['cv ' + str(count)] = listofper\n",
    "#    resultsdf['predictions ' + str(count)] = listofpre\n",
    "#print(accuracy)   \n",
    "#resultsdf.to_pickle('results_df.pickle')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Part 3: Results </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0, 31.451612903225808], [1, 30.64516129032258], [2, 71.7741935483871], [3, 65.32258064516128], [4, 64.51612903225806], [5, 66.93548387096774], [6, 75.80645161290323])\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('accuracy.pkl', 'rb') as f:\n",
    "   acc = pickle.load(f)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown, index 6 is our most \"accurate\" optimizing funcion. these indexes correspond to the index in optimizers = [ada,adad,adam,adamax,nadam,rms,sgd]. so our SGD optimizer was out best function, and overall my model performed a lot better than I expected! \n",
    "Some notes on what I called a \"success\". I initally tried to use percents. a guess has to be within 5%. That was very troublesome for all the compounds with low retention times(if RT is 2, and the guess is 2.8, it's pretty close but it's 30% off)!\n",
    "So a \"correct\" guess is something that is within 5 mins of the actual value. Although this is really high of a range, this was more of a proof of concept study and it shows the network can be remotely close to the actual value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          RT          0  CVsimplesNN       cv 0  predictions 0       cv 1  \\\n",
      "0     2.3850   1.162806   -51.245035 -13.166974       2.070968 -29.540372   \n",
      "1    34.7800  34.321083    -1.319485 -89.978984       3.485309 -94.415099   \n",
      "2    27.8200  26.250219    -5.642634 -88.353149       3.240154 -93.308797   \n",
      "3    32.6475  33.724678     3.299420 -88.671725       3.698399 -93.598508   \n",
      "4    16.9000  22.545456    33.405065 -82.912919       2.887717 -89.493549   \n",
      "5    59.5400  57.148415    -4.016771 -93.847573       3.663155 -96.526030   \n",
      "6     2.1000   3.821881    81.994336 -37.535610       1.311752 -15.583270   \n",
      "7    52.8000  55.108494     4.372147 -93.269020       3.553958 -96.395347   \n",
      "8     1.4000   0.986148   -29.560840 -48.183456       0.725432 -21.200897   \n",
      "9    42.2000  39.286201    -6.904736 -91.297339       3.672523 -95.498609   \n",
      "10    2.2000  12.565017   471.137125  -9.944166       1.981228 -27.093950   \n",
      "11   21.5950  19.656458    -8.976810 -84.039863       3.446592 -91.890412   \n",
      "12   54.9000  50.822430    -7.427268 -93.378867       3.635002 -96.443128   \n",
      "13    2.4000   1.340395   -44.150224 -20.388838       1.910668 -28.338597   \n",
      "14   48.0800  37.181129   -22.668200 -92.484857       3.613281 -96.016504   \n",
      "15   28.9000  26.587513    -8.001685 -87.718880       3.549244 -93.837286   \n",
      "16   25.4900  16.433216   -35.530733 -88.884836       2.833255 -94.813148   \n",
      "17    2.1100  12.661916   500.090795  -1.205002       2.084574 -22.438301   \n",
      "18   24.6000  24.500301    -0.405279 -86.712845       3.268640 -92.387414   \n",
      "19   58.9000  46.081608   -21.762975 -93.735226       3.689952 -96.650998   \n",
      "20   27.8100  25.577272    -8.028506 -87.580339       3.453908 -93.299752   \n",
      "21   44.2500  43.710552    -1.219091 -92.417502       3.355255 -95.645484   \n",
      "22   15.1000  23.692085    56.901227 -87.155870       1.939464 -89.208280   \n",
      "23   18.0000  19.093374     6.074301 -87.072282       2.326989 -91.655315   \n",
      "24   27.1000  30.625347    13.008661 -87.568481       3.368942 -93.161190   \n",
      "25   20.7000  38.611843    86.530643 -91.624583       1.733711 -91.987503   \n",
      "26   38.4250  39.850246     3.709164 -91.154562       3.398860 -95.261308   \n",
      "27   56.1200  55.580853    -0.960705 -93.451466       3.675037 -96.632670   \n",
      "28   22.6000  21.943130    -2.906502 -84.933164       3.405105 -92.114091   \n",
      "29   20.2000  27.225657    34.780478 -83.440318       3.345056 -90.823159   \n",
      "..       ...        ...          ...        ...            ...        ...   \n",
      "94   57.8600  54.487644    -5.828475 -93.656751       3.670204 -96.544785   \n",
      "95   21.7000  28.941719    33.371977 -82.964662       3.696668 -90.150407   \n",
      "96    2.8000   2.083062   -25.604922 -45.361874       1.529868 -45.549360   \n",
      "97   18.2000  16.121620   -11.419669 -83.072001       3.080896 -90.085602   \n",
      "98    1.3050   0.984797   -24.536605 -10.807107       1.163967   9.057710   \n",
      "99   30.9850  31.240139     0.823427 -88.446950       3.579713 -94.265990   \n",
      "100  55.1050  55.519821     0.752783 -93.488977       3.587899 -96.339254   \n",
      "101   1.3000  12.784471   883.420812  56.329889       2.032289  25.144005   \n",
      "102  33.9800  33.142662    -2.464208 -89.390923       3.604964 -94.903340   \n",
      "103  15.5000  15.675670     1.133353 -84.733720       2.366273 -89.443071   \n",
      "104   1.4000   1.218810   -12.942154  -4.882916       1.331639  13.501685   \n",
      "105  26.0700  21.918474   -15.924533 -87.278134       3.316591 -93.372858   \n",
      "106  24.8800  28.057125    12.769795 -87.337769       3.150363 -93.901860   \n",
      "107  22.5000  25.981483    15.473260 -85.298132       3.307920 -91.702913   \n",
      "108   1.6000  17.319138   982.446098  13.061629       1.808986 -10.305157   \n",
      "109   1.5000   1.311182   -12.587849 -13.641874       1.295372   7.155943   \n",
      "110  23.1000  17.883221   -22.583460 -86.423021       3.136282 -92.337587   \n",
      "111   6.2000  12.924157   108.454147 -68.102488       1.977646 -73.859229   \n",
      "112  23.7000  20.397598   -13.934185 -86.495484       3.200570 -92.356584   \n",
      "113   2.4000   0.988150   -58.827076 -63.553272       0.874721 -38.077177   \n",
      "114  11.9400   3.836862   -67.865475 -73.015072       3.222000 -86.046507   \n",
      "115   1.2150   0.980742   -19.280530 -40.312919       0.725198 -22.667923   \n",
      "116  23.9000  17.470581   -26.901334 -92.693205       1.746324 -93.314879   \n",
      "117   3.9900  11.737039   194.161369 -61.079948       1.552910 -52.112469   \n",
      "118  27.2500  26.007278    -4.560446 -87.640620       3.367931 -93.047826   \n",
      "119  21.4000  19.381254    -9.433392 -85.369975       3.130825 -91.740440   \n",
      "120  30.3500  30.134892    -0.708759 -88.385746       3.524926 -93.855936   \n",
      "121  46.3000  32.492657   -29.821476 -92.203703       3.609686 -95.875693   \n",
      "122   1.2250   0.989189   -19.249870 -21.968032       0.955892 -19.961545   \n",
      "123  25.5900  34.255611    33.863272 -90.078215       2.538985 -92.829997   \n",
      "\n",
      "     predictions 1         cv 2  predictions 2         cv 3  predictions 3  \\\n",
      "0         1.680462   251.869835       8.392096   172.225134       6.492569   \n",
      "1         1.942429     0.860409      35.079250    -4.520683      33.207706   \n",
      "2         1.861493     6.057846      29.505293    -3.218306      26.924667   \n",
      "3         2.089927   -11.409801      28.922485     1.634402      33.181091   \n",
      "4         1.775590    29.855320      21.945549    42.120452      24.018356   \n",
      "5         2.068402   -10.565557      53.249268    -9.940905      53.621185   \n",
      "6         1.772751   453.189641      11.616982   571.218509      14.095589   \n",
      "7         1.903257     0.831104      53.238823     1.212335      53.440113   \n",
      "8         1.103187   -32.660069       0.942759   -34.785988       0.912996   \n",
      "9         1.899587    -1.808436      41.436840    -3.902876      40.552986   \n",
      "10        1.603933   307.479893       8.964558   464.698479      12.423367   \n",
      "11        1.751266     0.185141      21.634981     5.627112      22.810175   \n",
      "12        1.952723    -3.023690      53.239994    -2.331347      53.620090   \n",
      "13        1.719874   -58.223904       1.002626    40.382489       3.369180   \n",
      "14        1.915265   -10.939624      42.820229     1.950585      49.017841   \n",
      "15        1.781024   -14.404364      24.737139    -5.722450      27.246212   \n",
      "16        1.322129   -14.397939      21.819965    25.014454      31.866184   \n",
      "17        1.636552   322.098060       8.906269   336.247423       9.204821   \n",
      "18        1.872696    40.706923      34.613903    50.453149      37.011475   \n",
      "19        1.972562   -10.891405      52.484962   -23.430192      45.099617   \n",
      "20        1.863339    -9.493571      25.169838    14.091930      31.728966   \n",
      "21        1.926873     0.042423      44.268772    19.083676      52.694527   \n",
      "22        1.629550    27.221809      19.210493    34.275879      20.275658   \n",
      "23        1.502043    17.273861      21.109295    15.904978      20.862896   \n",
      "24        1.853317    17.353475      31.802792     8.491433      29.401178   \n",
      "25        1.658587    73.103462      35.832417    47.050277      30.439407   \n",
      "26        1.820843     8.080981      41.530117    34.439919      51.658539   \n",
      "27        1.889745    -5.115346      53.249268    -4.452886      53.621040   \n",
      "28        1.782215    -6.539377      21.122101     7.154661      24.216953   \n",
      "29        1.853722     3.804711      20.968552    25.306724      25.311958   \n",
      "..             ...          ...            ...          ...            ...   \n",
      "94        1.999187    -7.968813      53.249245    -7.326011      53.621170   \n",
      "95        2.137362    32.452723      28.742241    30.295371      28.274096   \n",
      "96        1.524618   740.192522      23.525391   620.913751      20.185585   \n",
      "97        1.804420   -17.658926      14.986075     6.773188      19.432720   \n",
      "98        1.423203   -27.383725       0.947642   -32.595537       0.879628   \n",
      "99        1.776683     6.727227      33.069431     8.491541      33.616104   \n",
      "100       2.017254    -3.488374      53.182732    -2.694366      53.620270   \n",
      "101       1.626872   578.136459       8.815774   605.534128       9.171944   \n",
      "102       1.731845    -3.593608      32.758892     1.687536      34.553425   \n",
      "103       1.636324    19.327065      18.495695    38.939150      21.535568   \n",
      "104       1.589024   -15.016557       1.189768    14.693863       1.605714   \n",
      "105       1.727696    10.449321      28.794138     0.938338      26.314625   \n",
      "106       1.517217    19.690519      29.779001    21.696831      30.278172   \n",
      "107       1.866845    -7.798063      20.745436     1.174791      22.764328   \n",
      "108       1.435117  1021.790171      17.948643  1019.005084      17.904081   \n",
      "109       1.607339    -0.931692       1.486025    15.440035       1.731601   \n",
      "110       1.770017   -12.815358      20.139652     2.315399      23.634857   \n",
      "111       1.620728    73.306327      10.744992    92.233347      11.918468   \n",
      "112       1.811490   -13.007841      20.617142     4.977789      24.879736   \n",
      "113       1.486148    24.267578       2.982422    -3.176218       2.323771   \n",
      "114       1.666047   -19.717931       9.585679    23.163627      14.705737   \n",
      "115       0.939585  2825.055547      35.539425  1610.302722      20.780178   \n",
      "116       1.597744   -55.374933      10.665391   -56.394243      10.421776   \n",
      "117       1.910712   274.587640      14.946047   317.986705      16.677670   \n",
      "118       1.894467     6.867939      29.121513   -20.289367      21.721148   \n",
      "119       1.767546    -4.012635      20.541296    12.038666      23.976274   \n",
      "120       1.864723    14.856387      34.858913    -2.195146      29.683773   \n",
      "121       1.909554   -12.159139      40.670319   -30.434587      32.208786   \n",
      "122       0.980471    -1.111486       1.211384    11.316438       1.363626   \n",
      "123       1.834804    30.543770      33.406151    32.479740      33.901566   \n",
      "\n",
      "            cv 4  predictions 4         cv 5  predictions 5         cv 6  \\\n",
      "0     144.833149       5.839271   541.541391      15.300762     8.510953   \n",
      "1       3.232442      35.904243    -0.522424      34.598301    -6.747938   \n",
      "2       8.259209      30.117712     3.937261      28.915346     2.486216   \n",
      "3      -8.064306      30.014706     1.082227      33.000820    -6.292100   \n",
      "4      23.862125      20.932699    38.822014      23.460920    25.328640   \n",
      "5     -11.954276      52.422424   -11.654238      52.601067    -7.003024   \n",
      "6     -11.568295       1.857066   -56.897534       0.905152     0.958994   \n",
      "7      -0.715113      52.422421    -0.458423      52.557953     4.022532   \n",
      "8     -54.625717       0.635240   -38.730802       0.857769   -58.072373   \n",
      "9     -10.409123      37.807350    -8.085864      38.787766    -2.829437   \n",
      "10    559.307263      14.504760   604.546235      15.500017   423.600362   \n",
      "11      7.384726      23.189732   -19.654429      17.350626   -37.941403   \n",
      "12     -4.512888      52.422424    -4.187659      52.600975     0.855669   \n",
      "13    -73.508420       0.635798   -33.440263       1.597434    37.285918   \n",
      "14      8.887344      52.353035    -2.006774      47.115143   -20.762406   \n",
      "15    -20.311245      23.030050    -5.801707      27.223307   -13.612359   \n",
      "16     51.324716      38.572670    12.142746      28.585186    40.581052   \n",
      "17    585.678817      14.467823   628.220013      15.365442   324.141093   \n",
      "18      5.428192      25.935335    45.856609      35.880726    61.831305   \n",
      "19    -34.510780      38.573151   -31.991817      40.056820   -29.149051   \n",
      "20    -12.350986      24.375191   -25.270897      20.782164   -10.210860   \n",
      "21      0.747646      44.580833     8.666561      48.084953    22.440360   \n",
      "22    -79.242407       3.134397   -17.569280      12.447039   -41.367263   \n",
      "23     12.856134      20.314104    16.908868      21.043596    11.973317   \n",
      "24    -10.961123      24.129536     1.254945      27.440090    18.105843   \n",
      "25     44.796731      29.972923    20.144388      24.869888    80.184608   \n",
      "26      5.841037      40.669418    25.884017      48.370934    23.831973   \n",
      "27     -6.588695      52.422424    -6.270387      52.601059    -1.331999   \n",
      "28      5.339354      23.806694     0.112248      22.625368    -3.688811   \n",
      "29     20.513331      24.343693     5.860144      21.383749    13.951759   \n",
      "..           ...            ...          ...            ...          ...   \n",
      "94     -9.397815      52.422424    -9.089066      52.601067    -4.299735   \n",
      "95     38.247705      29.999752    33.626542      28.996960    30.018023   \n",
      "96    -56.837927       1.208538    96.528418       5.502796   -68.816612   \n",
      "97    -11.160438      16.168800     2.067717      18.576324    -6.791708   \n",
      "98    -51.325207       0.635206   -34.275159       0.857709   -53.707539   \n",
      "99     -3.411964      29.927803    10.248469      34.160488     4.984605   \n",
      "100    -4.868241      52.422356    -4.544028      52.601013     0.435396   \n",
      "101  1012.803386      14.466444  1082.314213      15.370085   541.471276   \n",
      "102    -6.782529      31.675297     0.491565      34.147034    -1.692030   \n",
      "103    48.875489      23.075701    23.807489      19.190161    -6.494134   \n",
      "104    23.483011       1.728762   -34.520981       0.916706    52.446679   \n",
      "105    12.079164      29.219038    -5.023608      24.760345    17.213231   \n",
      "106    81.607173      45.183865    26.578938      31.492840    12.067373   \n",
      "107    28.003048      28.800686    12.402039      25.290459   -19.458186   \n",
      "108  1002.441430      17.639063  1053.661609      18.458586  1003.119850   \n",
      "109   -49.299292       0.760511     7.649597       1.614744     6.452751   \n",
      "110   -20.919270      18.267649   -16.973461      19.179131   -16.957442   \n",
      "111    49.115516       9.245162    66.553343      10.326307    61.486841   \n",
      "112   -14.401895      20.286751    -9.317210      21.491821   -12.753487   \n",
      "113    51.038051       3.624913    66.972955       4.007351    96.232736   \n",
      "114    15.535399      13.794927   -67.257322       3.909476    -3.638503   \n",
      "115   656.283042       9.188839  1150.314281      15.191319   -51.319488   \n",
      "116   -11.235714      21.214664   -37.615726      14.909842   -39.894668   \n",
      "117   137.515074       9.476851   362.997886      18.473616   327.885175   \n",
      "118   -27.846849      19.661734     2.854821      28.027939   -14.793263   \n",
      "119    -7.328766      19.831644   -10.349445      19.185219    -6.658253   \n",
      "120    -8.343175      27.817846    -4.152589      29.089689     8.089026   \n",
      "121   -17.749615      38.081928   -38.649604      28.405233   -16.664824   \n",
      "122   -47.001190       0.649235   -17.512855       1.010468    79.248946   \n",
      "123    50.076213      38.404503    33.370477      34.129505    20.527343   \n",
      "\n",
      "     predictions 6  \n",
      "0         2.587986  \n",
      "1        32.433067  \n",
      "2        28.511665  \n",
      "3        30.593287  \n",
      "4        21.180540  \n",
      "5        55.370399  \n",
      "6         2.120139  \n",
      "7        54.923897  \n",
      "8         0.586987  \n",
      "9        41.005978  \n",
      "10       11.519208  \n",
      "11       13.401554  \n",
      "12       55.369762  \n",
      "13        3.294862  \n",
      "14       38.097435  \n",
      "15       24.966028  \n",
      "16       35.834110  \n",
      "17        8.949377  \n",
      "18       39.810501  \n",
      "19       41.731209  \n",
      "20       24.970360  \n",
      "21       54.179859  \n",
      "22        8.853543  \n",
      "23       20.155197  \n",
      "24       32.006683  \n",
      "25       37.298214  \n",
      "26       47.582436  \n",
      "27       55.372482  \n",
      "28       21.766329  \n",
      "29       23.018255  \n",
      "..             ...  \n",
      "94       55.372173  \n",
      "95       28.213911  \n",
      "96        0.873135  \n",
      "97       16.963909  \n",
      "98        0.604117  \n",
      "99       32.529480  \n",
      "100      55.344925  \n",
      "101       8.339127  \n",
      "102      33.405048  \n",
      "103      14.493409  \n",
      "104       2.134254  \n",
      "105      30.557489  \n",
      "106      27.882362  \n",
      "107      18.121908  \n",
      "108      17.649918  \n",
      "109       1.596791  \n",
      "110      19.182831  \n",
      "111      10.012184  \n",
      "112      20.677423  \n",
      "113       4.709586  \n",
      "114      11.505563  \n",
      "115       0.591468  \n",
      "116      14.365174  \n",
      "117      17.072618  \n",
      "118      23.218836  \n",
      "119      19.975134  \n",
      "120      32.805019  \n",
      "121      38.584187  \n",
      "122       2.195800  \n",
      "123      30.842947  \n",
      "\n",
      "[124 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "testdata = pd.read_pickle('results_df.pickle')\n",
    "print(testdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, you can see my results data frame. It uses the same indexes as accuracy, and inclused the actual values, the predictions, and the cv. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Conclusion </h2>\n",
    "Overall, the time put into this project was worth it. I think this will prove as a straight forward proof of concept for my PI(Dr. Forsberg) that we should try to implement a similar sort of algorithm in out lab. The eventual goal will be to have our model help identify whether or not our guess of what a compound is and where it elutes matches up reasonablly well with our model. \n",
    "\n",
    "<h3> Future Works </h3>\n",
    "Implementing into metabolomics workflow, creating a model based on compunds we have actually run on our system!\n",
    "Thanks For a great semester Scott Kelley! Hope to see you around!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
